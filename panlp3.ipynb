{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "panlp3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zapper59/NLP-Question-Answering/blob/master/panlp3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Z7rWB4XZyYHS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "### Only needs to be run once per \"runtime session\"\n",
        "\n",
        "git clone https://github.com/huggingface/pytorch-pretrained-BERT.git\n",
        "cd pytorch-pretrained-BERT/\n",
        "git checkout b8e2a9c5840e\n",
        "python setup.py install\n",
        "cd ..\n",
        "\n",
        "git clone https://github.com/zapper59/NLP-Question-Answering.git\n",
        "rm pytorch-pretrained-BERT/examples/run_squad.py\n",
        "cp NLP-Question-Answering/bert_on_colab/run_squad.py pytorch-pretrained-BERT/examples/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oKKEHgUt2pir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Setup environment variables\n",
        "import os\n",
        "os.environ['pdir'] = 'NLP-Question-Answering/bert_on_colab'\n",
        "SQUAD_VERSION= 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nG_bOijUQZJJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "While training, you may see that the GPU's memory usage is getting high.\n",
        "Just ignore this."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "g0eGKd00XHFh",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "### Train and also evalute on test set\n",
        "\n",
        "python $pdir/format_data.py --v2\n",
        "\n",
        "rm -fr out\n",
        "python pytorch-pretrained-BERT/examples/run_squad.py \\\n",
        "  --bert_model bert-base-cased \\\n",
        "  --do_train \\\n",
        "  --do_predict \\\n",
        "  --train_file $pdir/training.json \\\n",
        "  --predict_file $pdir/testing.json \\\n",
        "  --train_batch_size 12 \\\n",
        "  --learning_rate 3e-5 \\\n",
        "  --num_train_epochs 20.0 \\\n",
        "  --max_seq_length 384 \\\n",
        "  --doc_stride 128 \\\n",
        "  --output_dir out \\\n",
        "  --max_answer_length 8 \\\n",
        "  --version_2_with_negative\n",
        "\n",
        "### Save most recently trained model\n",
        "rm -fr saved_model\n",
        "mv out saved_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jgg86lycgVeX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Print human friendly prediction results on test set\n",
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "with open('NLP-Question-Answering/bert_on_colab/testing.json') as f:\n",
        "  test = json.load(f)\n",
        "\n",
        "if SQUAD_VERSION == 2:\n",
        "  with open('saved_model/nbest_predictions.json') as f:\n",
        "    nbest_preds = json.load(f)\n",
        "    for i in nbest_preds:\n",
        "      nbest_preds[i] = [{'text': p['text'], 'prob':p['probability']} for p in nbest_preds[i]]\n",
        "else:\n",
        "  with open('saved_model/predictions.json') as f:\n",
        "    preds = json.load(f)\n",
        "\n",
        "if SQUAD_VERSION == 2:\n",
        "  golds = []\n",
        "  for char in test['data']:\n",
        "    for para in char['paragraphs']:\n",
        "      qas = para['qas']\n",
        "      for qa in qas:\n",
        "        if not qa['is_impossible']:\n",
        "          qid = qa['id']\n",
        "          q = qa['question']\n",
        "          gold = qa['answers'][0]['text']\n",
        "          golds.append({'.question':q, 'gold': gold, 'preds': nbest_preds[qid][0:5]})\n",
        "else:\n",
        "  golds = []\n",
        "  for char in test['data']:\n",
        "    for para in char['paragraphs']:\n",
        "      for qa in para['qas']:\n",
        "        golds.append({'.question': qa['question'], 'gold': qa['answers'][0]['text']})\n",
        "\n",
        "    i = 0\n",
        "    for p in preds:\n",
        "      golds[i]['pred'] = preds[p]['text']\n",
        "      golds[i]['prob'] = preds[p]['probability']\n",
        "      i += 1\n",
        "\n",
        "pprint(golds)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O_0o97ci7iZY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From this point on, training is done and you only need run the code blocks below to test a query."
      ]
    },
    {
      "metadata": {
        "id": "Gb-gnWke_JQA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "query=\"Where was Jon Snow born and raised?\"\n",
        "python $pdir/format_query.py \"$query\"\n",
        "\n",
        "### Query using model in saved_model\n",
        "\n",
        "rm -fr out\n",
        "python pytorch-pretrained-BERT/examples/run_squad.py \\\n",
        "  --bert_model bert-base-cased \\\n",
        "  --do_predict \\\n",
        "  --predict_batch_size 32 \\\n",
        "  --predict_file $pdir/query.json \\\n",
        "  --max_seq_length 384 \\\n",
        "  --doc_stride 32 \\\n",
        "  --output_dir out \\\n",
        "  --max_answer_length 8 \\\n",
        "  --only_predict \\\n",
        "  --saved_model_dir saved_model \\\n",
        "  --version_2_with_negative"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D78ym2zp_W52",
        "colab_type": "code",
        "outputId": "afd42076-12e6-43ce-e8ea-330f6839767f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "### Get answer\n",
        "import collections\n",
        "import json\n",
        "import operator\n",
        "\n",
        "with open(\"out/predictions.json\") as f:\n",
        "    preds = json.load(f)\n",
        "\n",
        "freq = collections.Counter()\n",
        "sumscores = {}\n",
        "minscores = {}\n",
        "maxscores = {}\n",
        "if SQUAD_VERSION == 2:\n",
        "  for i in preds:\n",
        "    if preds[i]:\n",
        "      freq[preds[i]] += 1\n",
        "else:\n",
        "  for i in preds:\n",
        "      ans = preds[i]['text']\n",
        "      score = preds[i]['probability']\n",
        "      freq[ans] += 1\n",
        "      if ans in sumscores:\n",
        "          sumscores[ans] += score\n",
        "      else:\n",
        "          sumscores[ans] = score\n",
        "      if ans in minscores:\n",
        "          minscores[ans] = min(minscores[ans], score)\n",
        "      else:\n",
        "        minscores[ans] = score\n",
        "      if ans in maxscores:\n",
        "          maxscores[ans] = max(maxscores[ans], score)\n",
        "      else:\n",
        "        maxscores[ans] = score\n",
        "\n",
        "  avgscores = {}\n",
        "  for text in freq:\n",
        "      avgscores[text] = sumscores[text]/freq[text]\n",
        "\n",
        "  top_avgscores = sorted(avgscores.items(), key=operator.itemgetter(1), reverse=True)\n",
        "  top_minscores = sorted(minscores.items(), key=operator.itemgetter(1), reverse=True)\n",
        "  top_maxscores = sorted(maxscores.items(), key=operator.itemgetter(1), reverse=True)\n",
        "  print(top_avgscores)\n",
        "  print(top_minscores)\n",
        "  print(top_maxscores)\n",
        "\n",
        "\n",
        "print(freq.most_common(50))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Winterfell', 6), ('Daenerys Targaryen', 4), ('Aegon Targaryen', 4), ('Daenerys', 2), ('Aemon Targaryen', 2), ('Maester Luwin', 1), ('Wylla', 1), ('Jon Arryn', 1), ('Arya', 1), ('Aegon', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}